{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Noise and Anscombe Transform Denoising\n",
    "\n",
    "This notebook simulates Poisson noise (photon counting noise) in images and removes it using the **Anscombe Transform method**.\n",
    "\n",
    "## What This Notebook Does:\n",
    "\n",
    "1. **Adds Poisson Noise**: Simulates noise at 5 different intensity levels (scales: 0.1, 0.5, 1.0, 2.0, 5.0)\n",
    "2. **Applies Anscombe Transform Denoising**: Uses a 3-step process:\n",
    "   - Transform the noisy image to stabilize variance\n",
    "   - Apply a denoising filter (Gaussian, Median, or Bilateral)\n",
    "   - Inverse transform back to original domain\n",
    "3. **Calculates Quality Metrics**: PSNR, SSIM, MSE, Entropy, and more\n",
    "4. **Generates Visualizations**: Creates histograms and sample image comparisons\n",
    "\n",
    "## Output Directory Structure:\n",
    "```\n",
    "Data_Results/Data/\n",
    "├── bar_graph/   \n",
    "   └── poissson                   # Histogram visualizations of metrics\n",
    "├── finished/  \n",
    "   └── poissson                   # Side-by-side comparisons of original, noisy, denoised\n",
    "└── noised_image_data/     \n",
    "   └── poissson                   # CSV files with quality metrics\n",
    "\n",
    "Photo_Subset\n",
    "└──Noised_Images\n",
    "   ├── BW                        \n",
    "      └── scale_..                # Noised image output of black and white images (.. = scale, e.g: scale_0.5 is the black and white image noised with scale of 0.5)\n",
    "   └── Color                      \n",
    "      └── scale_..                # Noised image output of color images\n",
    "\n",
    "```\n",
    "\n",
    "## Applications:\n",
    "- Medical imaging (X-ray, CT scans)\n",
    "- Astronomy (telescope images)\n",
    "- Low-light photography\n",
    "- Any photon-limited imaging scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n",
      "Random seed set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(\"This is a seed.\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for nice-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print('Random seed set for reproducibility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Input and Output Paths\n",
    "\n",
    "**IMPORTANT**: Update `base_path` to point to your folder containing original images.\n",
    "\n",
    "The notebook will automatically create the output directory structure if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: ../../Data_Results/Data\n",
      "Input path verified: ../../Photos_Subset/Original\n"
     ]
    }
   ],
   "source": [
    "# ============ INPUT PATH ============\n",
    "# Update this to point to your images folder\n",
    "base_path = \"../../Photos_Subset/Original\"\n",
    "\n",
    "# ============ OUTPUT PATH ============\n",
    "# All results will be saved under this directory\n",
    "output_base = \"../../Data_Results/Data\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "Path(output_base).mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory: {output_base}\")\n",
    "\n",
    "# Verify input path exists\n",
    "if not os.path.exists(base_path):\n",
    "    raise FileNotFoundError(f\"Input folder not found at: {base_path}\")\n",
    "\n",
    "if not os.path.isdir(base_path):\n",
    "    raise NotADirectoryError(f\"{base_path} is not a directory\")\n",
    "\n",
    "print(f\"Input path verified: {base_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Poisson Noise Function\n",
    "\n",
    "Poisson noise models the randomness in photon counting. This is the primary noise source in:\n",
    "- Low-light imaging\n",
    "- Medical X-rays\n",
    "- Astronomy\n",
    "\n",
    "The `scale` parameter controls noise intensity:\n",
    "- **Lower scale** (e.g., 0.1) = more noise (fewer photons)\n",
    "- **Higher scale** (e.g., 5.0) = less noise (more photons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson noise function defined\n"
     ]
    }
   ],
   "source": [
    "def add_poisson_noise(image, scale=1.0):\n",
    "    \"\"\"\n",
    "    Add Poisson noise to an image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : numpy array\n",
    "        Input image (BGR format from cv2)\n",
    "    scale : float\n",
    "        Noise intensity control\n",
    "        - scale < 1.0: more noise (lower photon count)\n",
    "        - scale = 1.0: standard Poisson noise\n",
    "        - scale > 1.0: less noise (higher photon count)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy array : Image with Poisson noise added\n",
    "    \"\"\"\n",
    "    # Normalize to [0, 1] range\n",
    "    image_normalized = image.astype(np.float64) / 255.0\n",
    "    \n",
    "    # Scale to control noise level\n",
    "    scaled_image = image_normalized / scale\n",
    "    \n",
    "    # Apply Poisson noise (models photon counting)\n",
    "    noisy = np.random.poisson(scaled_image * 255) / 255.0\n",
    "    \n",
    "    # Scale back\n",
    "    noisy = noisy * scale\n",
    "    \n",
    "    # Convert back to uint8 [0, 255]\n",
    "    noisy = np.clip(noisy * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return noisy\n",
    "\n",
    "print(\"Poisson noise function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Anscombe Transform Functions\n",
    "\n",
    "The **Anscombe Transform** converts Poisson-distributed noise into approximately Gaussian noise with stable variance. This makes standard denoising filters more effective.\n",
    "\n",
    "**Three-step denoising process:**\n",
    "1. Apply Anscombe transform: `y = 2√(x + 3/8)`\n",
    "2. Apply denoising filter (Gaussian, Median, or Bilateral)\n",
    "3. Apply inverse transform: `x = (y/2)² - 3/8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anscombe transform functions defined\n"
     ]
    }
   ],
   "source": [
    "def anscombe_transform(image):\n",
    "    \"\"\"\n",
    "    Apply Anscombe transform to stabilize Poisson noise variance.\n",
    "    \n",
    "    Formula: f(x) = 2 * sqrt(x + 3/8)\n",
    "    \n",
    "    This transforms Poisson noise -> approximately Gaussian noise\n",
    "    \"\"\"\n",
    "    image_float = image.astype(np.float64)\n",
    "    transformed = 2 * np.sqrt(image_float + 3.0/8.0)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def inverse_anscombe_transform(transformed_image):\n",
    "    \"\"\"\n",
    "    Apply inverse Anscombe transform to recover the image.\n",
    "    \n",
    "    Formula: f^(-1)(y) = (y/2)^2 - 3/8\n",
    "    \"\"\"\n",
    "    recovered = (transformed_image / 2.0) ** 2 - 3.0/8.0\n",
    "    recovered = np.maximum(recovered, 0)  # Ensure non-negative\n",
    "    recovered = np.clip(recovered, 0, 255).astype(np.uint8)\n",
    "    return recovered\n",
    "\n",
    "\n",
    "def denoise_with_anscombe(noisy_image, filter_type='gaussian', kernel_size=5):\n",
    "    \"\"\"\n",
    "    Denoise image using the Anscombe transform method.\n",
    "    \n",
    "    Process:\n",
    "    1. Apply Anscombe transform (stabilize variance)\n",
    "    2. Apply denoising filter in transformed domain\n",
    "    3. Apply inverse Anscombe transform (recover image)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    noisy_image : numpy array\n",
    "        Noisy input image\n",
    "    filter_type : str\n",
    "        'gaussian', 'median', or 'bilateral'\n",
    "    kernel_size : int\n",
    "        Filter kernel size (must be odd number)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy array : Denoised image\n",
    "    \"\"\"\n",
    "    # Handle color images by processing each channel separately\n",
    "    if len(noisy_image.shape) == 3:\n",
    "        channels = cv2.split(noisy_image)\n",
    "        denoised_channels = []\n",
    "        \n",
    "        for channel in channels:\n",
    "            # Step 1: Apply Anscombe transform\n",
    "            transformed = anscombe_transform(channel)\n",
    "            \n",
    "            # Step 2: Apply denoising filter\n",
    "            if filter_type == 'gaussian':\n",
    "                filtered = cv2.GaussianBlur(transformed, (kernel_size, kernel_size), 0)\n",
    "            elif filter_type == 'median':\n",
    "                filtered = cv2.medianBlur(transformed.astype(np.float32), kernel_size).astype(np.float64)\n",
    "            elif filter_type == 'bilateral':\n",
    "                filtered = cv2.bilateralFilter(transformed.astype(np.float32), kernel_size, 75, 75).astype(np.float64)\n",
    "            else:\n",
    "                filtered = transformed\n",
    "            \n",
    "            # Step 3: Apply inverse Anscombe transform\n",
    "            denoised_channel = inverse_anscombe_transform(filtered)\n",
    "            denoised_channels.append(denoised_channel)\n",
    "        \n",
    "        denoised = cv2.merge(denoised_channels)\n",
    "    else:\n",
    "        # Grayscale image\n",
    "        transformed = anscombe_transform(noisy_image)\n",
    "        \n",
    "        if filter_type == 'gaussian':\n",
    "            filtered = cv2.GaussianBlur(transformed, (kernel_size, kernel_size), 0)\n",
    "        elif filter_type == 'median':\n",
    "            filtered = cv2.medianBlur(transformed.astype(np.float32), kernel_size).astype(np.float64)\n",
    "        elif filter_type == 'bilateral':\n",
    "            filtered = cv2.bilateralFilter(transformed.astype(np.float32), kernel_size, 75, 75).astype(np.float64)\n",
    "        else:\n",
    "            filtered = transformed\n",
    "        \n",
    "        denoised = inverse_anscombe_transform(filtered)\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "print(\"Anscombe transform functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Image Quality Metric Functions\n",
    "\n",
    "These functions measure how well the denoising worked:\n",
    "\n",
    "- **PSNR** (Peak Signal-to-Noise Ratio): Higher is better (measures pixel accuracy)\n",
    "- **SSIM** (Structural Similarity): Closer to 1 is better (measures perceived quality)\n",
    "- **MSE** (Mean Squared Error): Lower is better (pixel-level error)\n",
    "- **Entropy**: Measures information content\n",
    "- **Sharpness**: Uses Laplacian variance to measure edge clarity\n",
    "- **Spatial Frequency**: Measures image detail\n",
    "- **Dynamic Range**: Measures contrast (max - min intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All metric calculation functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_entropy(image):\n",
    "    \"\"\"Calculate entropy (information content) of image.\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "\n",
    "    hist, _ = np.histogram(gray.flatten(), bins=256, range=(0, 256))\n",
    "    hist = hist / hist.sum()\n",
    "    hist = hist[hist > 0]\n",
    "    return entropy(hist, base=2)\n",
    "\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    \"\"\"Calculate image sharpness using Laplacian variance.\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    return laplacian.var()\n",
    "\n",
    "\n",
    "def calculate_spatial_frequency(image):\n",
    "    \"\"\"Calculate spatial frequency (measures image detail).\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "\n",
    "    gray = gray.astype(np.float64)\n",
    "    RF = np.sqrt(np.mean(np.diff(gray, axis=1) ** 2))  # Row frequency\n",
    "    CF = np.sqrt(np.mean(np.diff(gray, axis=0) ** 2))  # Column frequency\n",
    "    SF = np.sqrt(RF ** 2 + CF ** 2)\n",
    "    return SF\n",
    "\n",
    "\n",
    "def calculate_dynamic_range(image):\n",
    "    \"\"\"Calculate dynamic range (max - min intensity).\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    return np.max(gray) - np.min(gray)\n",
    "\n",
    "\n",
    "def calculate_noise_variance(original, noisy):\n",
    "    \"\"\"Calculate variance of the noise (difference between images).\"\"\"\n",
    "    if len(original.shape) == 3:\n",
    "        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "        noisy_gray = cv2.cvtColor(noisy, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        original_gray = original\n",
    "        noisy_gray = noisy\n",
    "\n",
    "    noise = noisy_gray.astype(np.float64) - original_gray.astype(np.float64)\n",
    "    return np.var(noise)\n",
    "\n",
    "\n",
    "def calculate_all_metrics(original, processed, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Calculate all quality metrics comparing original to processed image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original : numpy array\n",
    "        Original clean image\n",
    "    processed : numpy array\n",
    "        Noisy or denoised image to compare\n",
    "    prefix : str\n",
    "        Prefix for metric names (e.g., 'Noisy_' or 'Denoised_')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing all calculated metrics\n",
    "    \"\"\"\n",
    "    # Convert to grayscale for metric calculation\n",
    "    if len(original.shape) == 3:\n",
    "        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "        processed_gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        original_gray = original\n",
    "        processed_gray = processed\n",
    "\n",
    "    # Calculate standard metrics\n",
    "    psnr_value = psnr(original_gray, processed_gray, data_range=255)\n",
    "    ssim_value = ssim(original_gray, processed_gray, data_range=255)\n",
    "    mse_value = np.mean((original_gray.astype(np.float64) - processed_gray.astype(np.float64)) ** 2)\n",
    "    \n",
    "    # Calculate entropy difference\n",
    "    entropy_orig = calculate_entropy(original)\n",
    "    entropy_processed = calculate_entropy(processed)\n",
    "    entropy_diff = abs(entropy_processed - entropy_orig)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    noise_var = calculate_noise_variance(original, processed)\n",
    "    sharpness_value = calculate_sharpness(processed)\n",
    "    spatial_freq = calculate_spatial_frequency(processed)\n",
    "    dynamic_range = calculate_dynamic_range(processed)\n",
    "\n",
    "    return {\n",
    "        f\"{prefix}PSNR\": psnr_value,\n",
    "        f\"{prefix}SSIM\": ssim_value,\n",
    "        f\"{prefix}MSE\": mse_value,\n",
    "        f\"{prefix}Entropy_Diff\": entropy_diff,\n",
    "        f\"{prefix}Noise_Variance\": noise_var,\n",
    "        f\"{prefix}Sharpness\": sharpness_value,\n",
    "        f\"{prefix}Spatial_Freq\": spatial_freq,\n",
    "        f\"{prefix}Dynamic_Range\": dynamic_range\n",
    "    }\n",
    "\n",
    "print(\"All metric calculation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configure Processing Parameters\n",
    "\n",
    "Define the noise levels and denoising filters to test:\n",
    "\n",
    "**Noise Scales:**\n",
    "- 0.1 = Very high noise (low photon count)\n",
    "- 0.5 = High noise\n",
    "- 1.0 = Standard Poisson noise\n",
    "- 2.0 = Moderate noise\n",
    "- 5.0 = Low noise (high photon count)\n",
    "\n",
    "**Denoising Filters:**\n",
    "- Gaussian blur (kernel sizes 3, 5, 7)\n",
    "- Median filter (kernel sizes 3, 5)\n",
    "- Bilateral filter (kernel size 5)\n",
    "\n",
    "This creates **30 total combinations** to test (5 noise levels × 6 filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 5 noise levels\n",
      "Configured 6 denoising filters\n",
      "Total combinations to test: 30\n"
     ]
    }
   ],
   "source": [
    "# ============ NOISE LEVEL CONFIGURATIONS ============\n",
    "POISSON_PARAMS = [\n",
    "    {\"scale\": 0.1, \"name\": \"scale_0.1\"},   # Very high noise\n",
    "    {\"scale\": 0.5, \"name\": \"scale_0.5\"},   # High noise\n",
    "    {\"scale\": 1.0, \"name\": \"scale_1.0\"},   # Standard Poisson\n",
    "    {\"scale\": 2.0, \"name\": \"scale_2.0\"},   # Moderate noise\n",
    "    {\"scale\": 5.0, \"name\": \"scale_5.0\"},   # Low noise\n",
    "]\n",
    "\n",
    "# ============ DENOISING FILTER CONFIGURATIONS ============\n",
    "ANSCOMBE_FILTERS = [\n",
    "    {\"filter_type\": \"gaussian\", \"kernel_size\": 3, \"name\": \"gaussian_k3\"},\n",
    "    {\"filter_type\": \"gaussian\", \"kernel_size\": 5, \"name\": \"gaussian_k5\"},\n",
    "    {\"filter_type\": \"gaussian\", \"kernel_size\": 7, \"name\": \"gaussian_k7\"},\n",
    "    {\"filter_type\": \"median\", \"kernel_size\": 3, \"name\": \"median_k3\"},\n",
    "    {\"filter_type\": \"median\", \"kernel_size\": 5, \"name\": \"median_k5\"},\n",
    "    {\"filter_type\": \"bilateral\", \"kernel_size\": 5, \"name\": \"bilateral_k5\"},\n",
    "]\n",
    "\n",
    "print(f\"Configured {len(POISSON_PARAMS)} noise levels\")\n",
    "print(f\"Configured {len(ANSCOMBE_FILTERS)} denoising filters\")\n",
    "print(f\"Total combinations to test: {len(POISSON_PARAMS) * len(ANSCOMBE_FILTERS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setup Output Directories and Load Images\n",
    "\n",
    "This cell:\n",
    "1. Creates the output directory structure (if it doesn't exist)\n",
    "2. Scans the input folder for image files\n",
    "3. Separates color and black & white images\n",
    "4. Selects 5 sample images for detailed comparison visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ready (cleaned): ../../Data_Results/Data\\noised_image_data\\poisson\n",
      "Directory ready (cleaned scale_* folders): ../../Photos_Subset/Noised_Images/BW\n",
      "Directory ready (cleaned scale_* folders): ../../Photos_Subset/Noised_Images/Color\n",
      "Directory ready (cleaned): ../../Data_Results/Data\\finished\\poisson\n",
      "Directory ready (cleaned): ../../Data_Results/Data\\bar_graphs\\poisson\n",
      "\n",
      "======================================================================\n",
      "IMAGE INVENTORY\n",
      "======================================================================\n",
      "Color images found: 80\n",
      "B&W images found: 80\n",
      "Total images: 160\n",
      "Sample images selected: 5\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============ HELPER FUNCTION FOR DIRECTORY CLEANUP ============\n",
    "def clean_directory(directory_path, pattern=None):\n",
    "    \"\"\"\n",
    "    Clean all files/folders in directory, optionally matching a pattern.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    directory_path : str\n",
    "        Path to directory to clean\n",
    "    pattern : str, optional\n",
    "        If provided, only delete items matching this pattern (e.g., 'scale_*')\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        return\n",
    "    \n",
    "    if pattern:\n",
    "        # Delete only items matching pattern\n",
    "        items = glob.glob(os.path.join(directory_path, pattern))\n",
    "        for item in items:\n",
    "            if os.path.isfile(item):\n",
    "                os.remove(item)\n",
    "            elif os.path.isdir(item):\n",
    "                shutil.rmtree(item)\n",
    "    else:\n",
    "        # Delete all items in directory\n",
    "        for item in os.listdir(directory_path):\n",
    "            item_path = os.path.join(directory_path, item)\n",
    "            if os.path.isfile(item_path):\n",
    "                os.remove(item_path)\n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "\n",
    "# ============ CREATE OUTPUT DIRECTORIES ============\n",
    "# CSV metrics: ../../Data_Results/Data/noised_images_data/poisson\n",
    "metrics_root = os.path.join(output_base, \"noised_images_data\", \"poisson\")\n",
    "Path(metrics_root).mkdir(parents=True, exist_ok=True)\n",
    "clean_directory(metrics_root)  # Clean all existing files\n",
    "print(f\"Directory ready (cleaned): {metrics_root}\")\n",
    "\n",
    "# Noised images: ../../Photos_Subset/Noised_Images/BW and .../Color\n",
    "noised_root_bw = \"../../Photos_Subset/Noised_Images/BW\"\n",
    "noised_root_color = \"../../Photos_Subset/Noised_Images/Color\"\n",
    "Path(noised_root_bw).mkdir(parents=True, exist_ok=True)\n",
    "Path(noised_root_color).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Clean only scale_* folders (preserve other noise type folders)\n",
    "clean_directory(noised_root_bw, \"scale_*\")\n",
    "clean_directory(noised_root_color, \"scale_*\")\n",
    "print(f\"Directory ready (cleaned scale_* folders): {noised_root_bw}\")\n",
    "print(f\"Directory ready (cleaned scale_* folders): {noised_root_color}\")\n",
    "\n",
    "# Sample images: ../../Data_Results/Data/finished/poisson\n",
    "sample_root = os.path.join(output_base, \"finished\", \"poisson\")\n",
    "Path(sample_root).mkdir(parents=True, exist_ok=True)\n",
    "clean_directory(sample_root)  # Clean all existing files\n",
    "print(f\"Directory ready (cleaned): {sample_root}\")\n",
    "\n",
    "# Bar graphs/histograms: ../../Data_Results/Data/bar_graphs/poisson\n",
    "graph_root = os.path.join(output_base, \"bar_graphs\", \"poisson\")\n",
    "Path(graph_root).mkdir(parents=True, exist_ok=True)\n",
    "clean_directory(graph_root)  # Clean all existing files\n",
    "print(f\"Directory ready (cleaned): {graph_root}\")\n",
    "\n",
    "# ============ LOAD IMAGE FILES ============\n",
    "# Get all image files from input directory\n",
    "all_files = [f for f in os.listdir(base_path)\n",
    "             if f.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"))\n",
    "             and os.path.isfile(os.path.join(base_path, f))]\n",
    "\n",
    "# Separate color and black & white images\n",
    "color_files = []\n",
    "bw_files = []\n",
    "\n",
    "for filename in all_files:\n",
    "    # Check if filename indicates black & white\n",
    "    if filename[-6:-4] == 'bw' or filename.lower().endswith('_bw.jpg') or filename.lower().endswith('_bw.png'):\n",
    "        bw_files.append(filename)\n",
    "    else:\n",
    "        color_files.append(filename)\n",
    "\n",
    "# ============ SELECT SAMPLE IMAGES ============\n",
    "# Choose 5 images for detailed comparison visualizations\n",
    "sample_images = []\n",
    "if len(all_files) >= 5:\n",
    "    # Try to get a mix of color and B&W\n",
    "    sample_color = color_files[:3] if len(color_files) >= 3 else color_files\n",
    "    sample_bw = bw_files[:2] if len(bw_files) >= 2 else bw_files\n",
    "    sample_images = sample_color + sample_bw\n",
    "    # If we don't have 5 yet, just take first 5 overall\n",
    "    if len(sample_images) < 5:\n",
    "        sample_images = all_files[:5]\n",
    "else:\n",
    "    sample_images = all_files\n",
    "\n",
    "# ============ SUMMARY ============\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"IMAGE INVENTORY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Color images found: {len(color_files)}\")\n",
    "print(f\"B&W images found: {len(bw_files)}\")\n",
    "print(f\"Total images: {len(all_files)}\")\n",
    "print(f\"Sample images selected: {len(sample_images)}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Processing Loop: Add Noise and Denoise\n",
    "\n",
    "This is the main processing cell that:\n",
    "\n",
    "**For each noise level (5 levels):**\n",
    "1. Adds Poisson noise to all images\n",
    "2. Saves noisy images to disk\n",
    "3. Calculates quality metrics for noisy images\n",
    "4. Saves metrics to CSV files\n",
    "\n",
    "**For each denoising filter (6 filters):**\n",
    "1. Applies Anscombe transform denoising\n",
    "2. Calculates quality metrics and improvements\n",
    "3. Saves denoised metrics to CSV files\n",
    "4. Stores sample images for visualization\n",
    "\n",
    "**Total iterations:** 5 noise levels × 6 filters = 30 combinations\n",
    "\n",
    "This cell may take several minutes depending on the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Processing Noise Level: scale_0.1 (scale=0.1)\n",
      "======================================================================\n",
      "\n",
      "  [1/2] Adding Poisson noise to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Adding noise (scale_0.1): 100%|██████████| 160/160 [00:07<00:00, 20.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_0.1.csv\n",
      "  Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_0.1_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k3): 100%|██████████| 160/160 [00:17<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_gaussian_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_gaussian_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k5): 100%|██████████| 160/160 [00:16<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_gaussian_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_gaussian_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k7): 100%|██████████| 160/160 [00:15<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_gaussian_k7.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_gaussian_k7_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k3): 100%|██████████| 160/160 [00:15<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_median_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_median_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k5): 100%|██████████| 160/160 [00:19<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_median_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_median_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with bilateral_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (bilateral_k5): 100%|██████████| 160/160 [00:15<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_bilateral_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.1_bilateral_k5_bw.csv\n",
      "\n",
      "======================================================================\n",
      "Processing Noise Level: scale_0.5 (scale=0.5)\n",
      "======================================================================\n",
      "\n",
      "  [1/2] Adding Poisson noise to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Adding noise (scale_0.5): 100%|██████████| 160/160 [00:06<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_0.5.csv\n",
      "  Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_0.5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k3): 100%|██████████| 160/160 [00:15<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_gaussian_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_gaussian_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k5): 100%|██████████| 160/160 [00:16<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_gaussian_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_gaussian_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k7): 100%|██████████| 160/160 [00:15<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_gaussian_k7.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_gaussian_k7_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k3): 100%|██████████| 160/160 [00:15<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_median_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_median_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k5): 100%|██████████| 160/160 [00:15<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_median_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_median_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with bilateral_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (bilateral_k5): 100%|██████████| 160/160 [00:15<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_bilateral_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_0.5_bilateral_k5_bw.csv\n",
      "\n",
      "======================================================================\n",
      "Processing Noise Level: scale_1.0 (scale=1.0)\n",
      "======================================================================\n",
      "\n",
      "  [1/2] Adding Poisson noise to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Adding noise (scale_1.0): 100%|██████████| 160/160 [00:06<00:00, 25.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_1.0.csv\n",
      "  Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_1.0_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k3): 100%|██████████| 160/160 [00:14<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_gaussian_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_gaussian_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k5): 100%|██████████| 160/160 [00:15<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_gaussian_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_gaussian_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k7): 100%|██████████| 160/160 [00:21<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_gaussian_k7.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_gaussian_k7_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k3): 100%|██████████| 160/160 [00:36<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_median_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_median_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k5): 100%|██████████| 160/160 [00:52<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_median_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_median_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with bilateral_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (bilateral_k5): 100%|██████████| 160/160 [00:29<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_bilateral_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_1.0_bilateral_k5_bw.csv\n",
      "\n",
      "======================================================================\n",
      "Processing Noise Level: scale_2.0 (scale=2.0)\n",
      "======================================================================\n",
      "\n",
      "  [1/2] Adding Poisson noise to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Adding noise (scale_2.0): 100%|██████████| 160/160 [00:06<00:00, 23.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_2.0.csv\n",
      "  Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_2.0_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k3): 100%|██████████| 160/160 [00:15<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_gaussian_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_gaussian_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k5): 100%|██████████| 160/160 [00:14<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_gaussian_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_gaussian_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k7): 100%|██████████| 160/160 [00:14<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_gaussian_k7.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_gaussian_k7_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k3): 100%|██████████| 160/160 [00:15<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_median_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_median_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k5): 100%|██████████| 160/160 [00:15<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_median_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_median_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with bilateral_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (bilateral_k5): 100%|██████████| 160/160 [00:16<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_bilateral_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_2.0_bilateral_k5_bw.csv\n",
      "\n",
      "======================================================================\n",
      "Processing Noise Level: scale_5.0 (scale=5.0)\n",
      "======================================================================\n",
      "\n",
      "  [1/2] Adding Poisson noise to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Adding noise (scale_5.0): 100%|██████████| 160/160 [00:06<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_5.0.csv\n",
      "  Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\noisy_scale_5.0_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k3): 100%|██████████| 160/160 [00:23<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_gaussian_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_gaussian_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k5): 100%|██████████| 160/160 [00:26<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_gaussian_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_gaussian_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with gaussian_k7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (gaussian_k7): 100%|██████████| 160/160 [00:15<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_gaussian_k7.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_gaussian_k7_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k3): 100%|██████████| 160/160 [00:16<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_median_k3.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_median_k3_bw.csv\n",
      "\n",
      "  [2/2] Denoising with median_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (median_k5): 100%|██████████| 160/160 [00:15<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_median_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_median_k5_bw.csv\n",
      "\n",
      "  [2/2] Denoising with bilateral_k5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Denoising (bilateral_k5): 100%|██████████| 160/160 [00:15<00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved color metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_bilateral_k5.csv\n",
      "    Saved B&W metrics: ../../Data_Results/Data\\noised_image_data\\poisson\\denoised_scale_5.0_bilateral_k5_bw.csv\n",
      "\n",
      "All processing complete!\n",
      "Sample data collected for 5 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============ MAIN PROCESSING LOOP ============\n",
    "\n",
    "# Dictionary to store sample images for visualization later\n",
    "sample_data = {}\n",
    "\n",
    "for poisson_config in POISSON_PARAMS:\n",
    "    param_name = poisson_config[\"name\"]\n",
    "    scale = poisson_config[\"scale\"]\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing Noise Level: {param_name} (scale={scale})\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Create output directories for this noise level (separate for BW and Color)\n",
    "    noise_output_dir_bw = os.path.join(noised_root_bw, param_name)\n",
    "    noise_output_dir_color = os.path.join(noised_root_color, param_name)\n",
    "    os.makedirs(noise_output_dir_bw, exist_ok=True)\n",
    "    os.makedirs(noise_output_dir_color, exist_ok=True)\n",
    "\n",
    "    # Store noisy images in memory for denoising\n",
    "    noisy_images_dict = {}\n",
    "    \n",
    "    # Separate metric storage for color vs B&W\n",
    "    noisy_metrics_color = []\n",
    "    noisy_metrics_bw = []\n",
    "\n",
    "    # -------- STEP 1: Add Poisson Noise --------\n",
    "    print(f\"\\n  [1/2] Adding Poisson noise to images...\")\n",
    "    for filename in tqdm(all_files, desc=f\"    Adding noise ({param_name})\"):\n",
    "        filepath = os.path.join(base_path, filename)\n",
    "        img = cv2.imread(filepath)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Add Poisson noise\n",
    "        noisy_img = add_poisson_noise(img, scale=scale)\n",
    "\n",
    "        # Determine if image is B&W or color and save to appropriate directory\n",
    "        is_bw = filename[-6:-4] == 'bw' or filename.lower().endswith('_bw.jpg') or filename.lower().endswith('_bw.png')\n",
    "        output_dir = noise_output_dir_bw if is_bw else noise_output_dir_color\n",
    "        \n",
    "        # Save noisy image to disk\n",
    "        output_filename = f\"noisy_{filename}\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        cv2.imwrite(output_path, noisy_img)\n",
    "\n",
    "        # Store in memory for denoising\n",
    "        noisy_images_dict[filename] = noisy_img\n",
    "\n",
    "        # Store for sample visualization\n",
    "        if filename in sample_images:\n",
    "            if filename not in sample_data:\n",
    "                sample_data[filename] = {'original': img, 'noisy': {}, 'denoised': {}}\n",
    "            sample_data[filename]['noisy'][param_name] = noisy_img\n",
    "\n",
    "        # Calculate quality metrics\n",
    "        noisy_metrics = calculate_all_metrics(img, noisy_img, prefix=\"Noisy_\")\n",
    "        noisy_metrics[\"Name\"] = output_filename\n",
    "        noisy_metrics[\"Noise_Level\"] = param_name\n",
    "        noisy_metrics[\"Scale\"] = scale\n",
    "\n",
    "        # Separate by color vs B&W\n",
    "        if is_bw:\n",
    "            noisy_metrics_bw.append(noisy_metrics)\n",
    "        else:\n",
    "            noisy_metrics_color.append(noisy_metrics)\n",
    "\n",
    "    # Save noisy metrics to CSV\n",
    "    column_order = [\"Name\", \"Noise_Level\", \"Scale\", \"Noisy_PSNR\", \"Noisy_SSIM\", \"Noisy_MSE\", \"Noisy_Entropy_Diff\",\n",
    "                    \"Noisy_Noise_Variance\", \"Noisy_Sharpness\", \"Noisy_Spatial_Freq\", \"Noisy_Dynamic_Range\"]\n",
    "    \n",
    "    if noisy_metrics_color:\n",
    "        df_color = pd.DataFrame(noisy_metrics_color)[column_order]\n",
    "        csv_path_color = os.path.join(metrics_root, f\"noisy_{param_name}.csv\")\n",
    "        df_color.to_csv(csv_path_color, index=False)\n",
    "        print(f\"  Saved color metrics: {csv_path_color}\")\n",
    "\n",
    "    if noisy_metrics_bw:\n",
    "        df_bw = pd.DataFrame(noisy_metrics_bw)[column_order]\n",
    "        csv_path_bw = os.path.join(metrics_root, f\"noisy_{param_name}_bw.csv\")\n",
    "        df_bw.to_csv(csv_path_bw, index=False)\n",
    "        print(f\"  Saved B&W metrics: {csv_path_bw}\")\n",
    "\n",
    "    # -------- STEP 2: Apply Anscombe Denoising --------\n",
    "    for filter_config in ANSCOMBE_FILTERS:\n",
    "        filter_name = filter_config[\"name\"]\n",
    "        filter_type = filter_config[\"filter_type\"]\n",
    "        kernel_size = filter_config[\"kernel_size\"]\n",
    "\n",
    "        print(f\"\\n  [2/2] Denoising with {filter_name}...\")\n",
    "\n",
    "        # Separate metric storage\n",
    "        denoised_metrics_color = []\n",
    "        denoised_metrics_bw = []\n",
    "\n",
    "        for filename in tqdm(all_files, desc=f\"    Denoising ({filter_name})\"):\n",
    "            filepath = os.path.join(base_path, filename)\n",
    "            img = cv2.imread(filepath)\n",
    "\n",
    "            if img is None or filename not in noisy_images_dict:\n",
    "                continue\n",
    "\n",
    "            noisy_img = noisy_images_dict[filename]\n",
    "\n",
    "            # Apply Anscombe transform denoising\n",
    "            denoised_img = denoise_with_anscombe(noisy_img, filter_type=filter_type, kernel_size=kernel_size)\n",
    "\n",
    "            # Store for sample visualization\n",
    "            if filename in sample_images:\n",
    "                if param_name not in sample_data[filename]['denoised']:\n",
    "                    sample_data[filename]['denoised'][param_name] = {}\n",
    "                sample_data[filename]['denoised'][param_name][filter_name] = denoised_img\n",
    "\n",
    "            # Calculate quality metrics\n",
    "            denoised_metrics = calculate_all_metrics(img, denoised_img, prefix=\"Denoised_\")\n",
    "            \n",
    "            # Calculate improvement over noisy\n",
    "            noisy_psnr = calculate_all_metrics(img, noisy_img, prefix=\"\")[\"PSNR\"]\n",
    "            noisy_ssim = calculate_all_metrics(img, noisy_img, prefix=\"\")[\"SSIM\"]\n",
    "            noisy_mse = calculate_all_metrics(img, noisy_img, prefix=\"\")[\"MSE\"]\n",
    "            \n",
    "            improvement_metrics = {\n",
    "                \"PSNR_Improvement\": denoised_metrics[\"Denoised_PSNR\"] - noisy_psnr,\n",
    "                \"SSIM_Improvement\": denoised_metrics[\"Denoised_SSIM\"] - noisy_ssim,\n",
    "                \"MSE_Reduction\": noisy_mse - denoised_metrics[\"Denoised_MSE\"],\n",
    "            }\n",
    "            \n",
    "            denoised_metrics[\"Name\"] = f\"denoised_{filename}\"\n",
    "            denoised_metrics[\"Noise_Level\"] = param_name\n",
    "            denoised_metrics[\"Scale\"] = scale\n",
    "            denoised_metrics[\"Filter\"] = filter_name\n",
    "            denoised_metrics.update(improvement_metrics)\n",
    "\n",
    "            # Separate by color vs B&W\n",
    "            is_bw = filename[-6:-4] == 'bw' or filename.lower().endswith('_bw.jpg') or filename.lower().endswith('_bw.png')\n",
    "            if is_bw:\n",
    "                denoised_metrics_bw.append(denoised_metrics)\n",
    "            else:\n",
    "                denoised_metrics_color.append(denoised_metrics)\n",
    "\n",
    "        # Save denoised metrics to CSV\n",
    "        denoised_column_order = [\"Name\", \"Noise_Level\", \"Scale\", \"Filter\", \n",
    "                                \"Denoised_PSNR\", \"Denoised_SSIM\", \"Denoised_MSE\", \n",
    "                                \"Denoised_Entropy_Diff\", \"Denoised_Noise_Variance\", \"Denoised_Sharpness\", \n",
    "                                \"Denoised_Spatial_Freq\", \"Denoised_Dynamic_Range\",\n",
    "                                \"PSNR_Improvement\", \"SSIM_Improvement\", \"MSE_Reduction\"]\n",
    "        \n",
    "        if denoised_metrics_color:\n",
    "            df_color = pd.DataFrame(denoised_metrics_color)[denoised_column_order]\n",
    "            csv_path_color = os.path.join(metrics_root, f\"denoised_{param_name}_{filter_name}.csv\")\n",
    "            df_color.to_csv(csv_path_color, index=False)\n",
    "            print(f\"    Saved color metrics: {csv_path_color}\")\n",
    "\n",
    "        if denoised_metrics_bw:\n",
    "            df_bw = pd.DataFrame(denoised_metrics_bw)[denoised_column_order]\n",
    "            csv_path_bw = os.path.join(metrics_root, f\"denoised_{param_name}_{filter_name}_bw.csv\")\n",
    "            df_bw.to_csv(csv_path_bw, index=False)\n",
    "            print(f\"    Saved B&W metrics: {csv_path_bw}\")\n",
    "\n",
    "print(\"\\nAll processing complete!\")\n",
    "print(f\"Sample data collected for {len(sample_data)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Sample Image Comparisons\n",
    "\n",
    "This cell creates side-by-side visual comparisons showing:\n",
    "- Original image\n",
    "- Noisy version (for each scale level)\n",
    "- All 6 denoised versions (using different filters)\n",
    "\n",
    "Saves comparison grids as PNG files for visual inspection of denoising effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING SAMPLE IMAGE COMPARISONS\n",
      "======================================================================\n",
      "\n",
      "Processing sample: BSDS300_10_46076.jpg\n",
      "  Saved: comparison_BSDS300_10_46076_scale_0.1.png\n",
      "  Saved: comparison_BSDS300_10_46076_scale_0.5.png\n",
      "  Saved: comparison_BSDS300_10_46076_scale_1.0.png\n",
      "  Saved: comparison_BSDS300_10_46076_scale_2.0.png\n",
      "  Saved: comparison_BSDS300_10_46076_scale_5.0.png\n",
      "Processing sample: BSDS300_10_46076_bw.jpg\n",
      "  Saved: comparison_BSDS300_10_46076_bw_scale_0.1.png\n",
      "  Saved: comparison_BSDS300_10_46076_bw_scale_0.5.png\n",
      "  Saved: comparison_BSDS300_10_46076_bw_scale_1.0.png\n",
      "  Saved: comparison_BSDS300_10_46076_bw_scale_2.0.png\n",
      "  Saved: comparison_BSDS300_10_46076_bw_scale_5.0.png\n",
      "Processing sample: BSDS300_11_66039.jpg\n",
      "  Saved: comparison_BSDS300_11_66039_scale_0.1.png\n",
      "  Saved: comparison_BSDS300_11_66039_scale_0.5.png\n",
      "  Saved: comparison_BSDS300_11_66039_scale_1.0.png\n",
      "  Saved: comparison_BSDS300_11_66039_scale_2.0.png\n",
      "  Saved: comparison_BSDS300_11_66039_scale_5.0.png\n",
      "Processing sample: BSDS300_11_66039_bw.jpg\n",
      "  Saved: comparison_BSDS300_11_66039_bw_scale_0.1.png\n",
      "  Saved: comparison_BSDS300_11_66039_bw_scale_0.5.png\n",
      "  Saved: comparison_BSDS300_11_66039_bw_scale_1.0.png\n",
      "  Saved: comparison_BSDS300_11_66039_bw_scale_2.0.png\n",
      "  Saved: comparison_BSDS300_11_66039_bw_scale_5.0.png\n",
      "Processing sample: BSDS300_12_249087.jpg\n",
      "  Saved: comparison_BSDS300_12_249087_scale_0.1.png\n",
      "  Saved: comparison_BSDS300_12_249087_scale_0.5.png\n",
      "  Saved: comparison_BSDS300_12_249087_scale_1.0.png\n",
      "  Saved: comparison_BSDS300_12_249087_scale_2.0.png\n",
      "  Saved: comparison_BSDS300_12_249087_scale_5.0.png\n",
      "\n",
      "All sample comparisons saved to: ../../Data_Results/Data\\finished\\poisson\n"
     ]
    }
   ],
   "source": [
    "# ============ CREATE SAMPLE COMPARISONS ============\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CREATING SAMPLE IMAGE COMPARISONS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for filename, data in sample_data.items():\n",
    "    print(f\"Processing sample: {filename}\")\n",
    "    \n",
    "    # Create a comparison for each noise level\n",
    "    for noise_level in POISSON_PARAMS:\n",
    "        param_name = noise_level[\"name\"]\n",
    "        scale = noise_level[\"scale\"]\n",
    "        \n",
    "        if param_name not in data['noisy']:\n",
    "            continue\n",
    "        \n",
    "        # Get images\n",
    "        original = data['original']\n",
    "        noisy = data['noisy'][param_name]\n",
    "        \n",
    "        # Create figure: 2 rows × 4 columns\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "        fig.suptitle(f'Sample: {filename} | Noise Level: {param_name} (scale={scale})', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "        noisy_rgb = cv2.cvtColor(noisy, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Position [0,0]: Original image\n",
    "        axes[0, 0].imshow(original_rgb)\n",
    "        axes[0, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Position [0,1]: Noisy image\n",
    "        axes[0, 1].imshow(noisy_rgb)\n",
    "        axes[0, 1].set_title(f'Noisy (scale={scale})', fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Positions [0,2], [0,3], [1,0], [1,1], [1,2], [1,3]: Denoised versions\n",
    "        positions = [(0, 2), (0, 3), (1, 0), (1, 1), (1, 2), (1, 3)]\n",
    "        \n",
    "        for idx, filter_config in enumerate(ANSCOMBE_FILTERS):\n",
    "            if idx >= 6:  # Only show first 6 filters\n",
    "                break\n",
    "                \n",
    "            filter_name = filter_config[\"name\"]\n",
    "            \n",
    "            if param_name in data['denoised'] and filter_name in data['denoised'][param_name]:\n",
    "                denoised = data['denoised'][param_name][filter_name]\n",
    "                denoised_rgb = cv2.cvtColor(denoised, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                row, col = positions[idx]\n",
    "                axes[row, col].imshow(denoised_rgb)\n",
    "                axes[row, col].set_title(f'Denoised: {filter_name}', fontsize=10)\n",
    "                axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save comparison image\n",
    "        sample_filename = os.path.splitext(filename)[0]\n",
    "        output_path = os.path.join(sample_root, f\"comparison_{sample_filename}_{param_name}.png\")\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved: comparison_{sample_filename}_{param_name}.png\")\n",
    "\n",
    "print(f\"\\nAll sample comparisons saved to: {sample_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Metric Distribution Visualizations\n",
    "\n",
    "This cell generates histogram visualizations showing how denoising quality varies across different noise levels.\n",
    "\n",
    "**Creates 4 visualizations (one for each metric):**\n",
    "1. **PSNR** - Higher values indicate better reconstruction\n",
    "2. **SSIM** - Values closer to 1.0 indicate better perceptual quality\n",
    "3. **MSE** - Lower values indicate less error\n",
    "4. **Entropy Difference** - Measures information preservation\n",
    "\n",
    "**Each visualization includes:**\n",
    "- Overlaid histograms by noise level (left plot)\n",
    "- Box plots showing distribution statistics (right plot)\n",
    "- Summary statistics printed to console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING METRIC DISTRIBUTION VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "Loaded 60 CSV files\n",
      "Total records: 4800\n",
      "Noise levels: ['scale_0.1', 'scale_0.5', 'scale_1.0', 'scale_2.0', 'scale_5.0']\n",
      "Filters tested: ['bilateral_k5', 'gaussian_k3', 'gaussian_k5', 'gaussian_k7', 'median_k3', 'median_k5']\n",
      "\n",
      "Creating visualizations for Peak Signal-to-Noise Ratio...\n",
      "  Saved: histogram_denoised_psnr_detailed.png\n",
      "\n",
      "Creating visualizations for Structural Similarity Index...\n",
      "  Saved: histogram_denoised_ssim_detailed.png\n",
      "\n",
      "Creating visualizations for Mean Squared Error...\n",
      "  Saved: histogram_denoised_mse_detailed.png\n",
      "\n",
      "Creating visualizations for Entropy Difference from Original...\n",
      "  Saved: histogram_denoised_entropy_diff_detailed.png\n",
      "\n",
      "======================================================================\n",
      "SUMMARY STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Peak Signal-to-Noise Ratio:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  Noise Level: scale_0.1\n",
      "                   mean       std        min        max\n",
      "Filter                                                 \n",
      "bilateral_k5  27.115578  5.684460  18.175011  37.245344\n",
      "gaussian_k3   29.622292  5.927118  20.934606  39.731975\n",
      "gaussian_k5   27.713795  5.676406  18.938618  37.737126\n",
      "gaussian_k7   26.168669  5.393964  17.478694  35.926237\n",
      "median_k3     30.573166  7.767289  19.360151  45.316758\n",
      "median_k5     28.186075  8.005009  16.361893  44.527736\n",
      "\n",
      "  Noise Level: scale_0.5\n",
      "                   mean       std        min        max\n",
      "Filter                                                 \n",
      "bilateral_k5  27.048237  5.628439  18.144425  37.092968\n",
      "gaussian_k3   29.406469  5.738853  20.882615  39.166459\n",
      "gaussian_k5   27.636521  5.614494  18.898330  37.565110\n",
      "gaussian_k7   26.138405  5.375604  17.453128  35.889426\n",
      "median_k3     30.056314  7.137436  19.382161  43.183913\n",
      "median_k5     27.998292  7.734520  16.397213  43.573044\n",
      "\n",
      "  Noise Level: scale_1.0\n",
      "                   mean       std        min        max\n",
      "Filter                                                 \n",
      "bilateral_k5  26.964483  5.558040  18.116947  36.878573\n",
      "gaussian_k3   29.163313  5.533909  20.843921  38.573662\n",
      "gaussian_k5   27.541461  5.537351  18.859877  37.336268\n",
      "gaussian_k7   26.098598  5.348795  17.429820  35.814180\n",
      "median_k3     29.588667  6.619392  19.392212  41.574716\n",
      "median_k5     27.809777  7.489067  16.417739  42.657385\n",
      "\n",
      "  Noise Level: scale_2.0\n",
      "                   mean       std        min        max\n",
      "Filter                                                 \n",
      "bilateral_k5  26.742073  5.374139  18.055565  36.324646\n",
      "gaussian_k3   28.665689  5.145491  20.744964  37.466329\n",
      "gaussian_k5   27.290534  5.337832  18.781952  36.738177\n",
      "gaussian_k7   25.957592  5.243215  17.378056  35.508880\n",
      "median_k3     28.856737  5.906151  19.354958  39.345953\n",
      "median_k5     27.449116  7.052790  16.444002  41.184698\n",
      "\n",
      "  Noise Level: scale_5.0\n",
      "                   mean       std        min        max\n",
      "Filter                                                 \n",
      "bilateral_k5  26.096866  4.877289  17.893358  35.031562\n",
      "gaussian_k3   27.497487  4.352619  20.438079  35.363337\n",
      "gaussian_k5   26.574978  4.807001  18.574747  35.355295\n",
      "gaussian_k7   25.497614  4.904667  17.240239  34.704092\n",
      "median_k3     27.496789  4.829647  19.227366  35.967900\n",
      "median_k5     26.672917  6.239004  16.445699  38.419387\n",
      "\n",
      "Structural Similarity Index:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  Noise Level: scale_0.1\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.863676  0.105389  0.520399  0.989782\n",
      "gaussian_k3   0.923151  0.059495  0.702900  0.991661\n",
      "gaussian_k5   0.883974  0.089419  0.581158  0.990766\n",
      "gaussian_k7   0.840332  0.120550  0.473458  0.988734\n",
      "median_k3     0.904880  0.085703  0.575572  0.991306\n",
      "median_k5     0.837277  0.138107  0.437210  0.991563\n",
      "\n",
      "  Noise Level: scale_0.5\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.858354  0.104873  0.519357  0.984863\n",
      "gaussian_k3   0.912846  0.059313  0.699428  0.982626\n",
      "gaussian_k5   0.878763  0.088956  0.579741  0.986079\n",
      "gaussian_k7   0.837844  0.120331  0.472978  0.986526\n",
      "median_k3     0.891394  0.086234  0.571007  0.980243\n",
      "median_k5     0.831393  0.138448  0.434146  0.987654\n",
      "\n",
      "  Noise Level: scale_1.0\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.852451  0.104819  0.517703  0.979726\n",
      "gaussian_k3   0.901866  0.061464  0.694334  0.974523\n",
      "gaussian_k5   0.872946  0.089041  0.577626  0.981200\n",
      "gaussian_k7   0.835014  0.120242  0.471903  0.984139\n",
      "median_k3     0.877472  0.089050  0.567948  0.975501\n",
      "median_k5     0.825329  0.138908  0.430527  0.983164\n",
      "\n",
      "  Noise Level: scale_2.0\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.841743  0.105716  0.514953  0.970445\n",
      "gaussian_k3   0.883306  0.068436  0.687097  0.971367\n",
      "gaussian_k5   0.862346  0.090219  0.574599  0.972166\n",
      "gaussian_k7   0.829492  0.120356  0.470694  0.979253\n",
      "median_k3     0.854063  0.097290  0.556719  0.974816\n",
      "median_k5     0.813949  0.140268  0.423398  0.974093\n",
      "\n",
      "  Noise Level: scale_5.0\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.816232  0.111931  0.502219  0.952099\n",
      "gaussian_k3   0.843503  0.090995  0.623977  0.970454\n",
      "gaussian_k5   0.837091  0.097269  0.560134  0.957370\n",
      "gaussian_k7   0.815167  0.121998  0.462753  0.968935\n",
      "median_k3     0.806878  0.122556  0.529166  0.973237\n",
      "median_k5     0.787130  0.145717  0.405018  0.954777\n",
      "\n",
      "Mean Squared Error:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  Noise Level: scale_0.1\n",
      "                    mean         std        min          max\n",
      "Filter                                                      \n",
      "bilateral_k5  233.287564  210.754989  12.261567   989.872533\n",
      "gaussian_k3   140.105659  133.709881   6.916444   524.348125\n",
      "gaussian_k5   204.050076  185.644932  10.948831   830.268463\n",
      "gaussian_k7   275.062318  240.974615  16.613328  1162.013025\n",
      "median_k3     148.514929  152.143213   1.911633   753.468792\n",
      "median_k5     251.770309  246.428589   2.292486  1502.764859\n",
      "\n",
      "  Noise Level: scale_0.5\n",
      "                    mean         std        min          max\n",
      "Filter                                                      \n",
      "bilateral_k5  234.726893  211.274490  12.699411   996.868408\n",
      "gaussian_k3   142.399029  134.046758   7.878336   530.663056\n",
      "gaussian_k5   205.539253  186.227959  11.391197   838.006451\n",
      "gaussian_k7   276.140886  241.733558  16.754742  1168.873647\n",
      "median_k3     151.238465  151.658661   3.123842   749.659814\n",
      "median_k5     252.660580  245.324702   2.856117  1490.592975\n",
      "\n",
      "  Noise Level: scale_1.0\n",
      "                    mean         std        min          max\n",
      "Filter                                                      \n",
      "bilateral_k5  236.524713  211.823926  13.342067  1003.195795\n",
      "gaussian_k3   145.210030  134.344388   9.030550   535.412222\n",
      "gaussian_k5   207.364486  186.788668  12.007528   845.459136\n",
      "gaussian_k7   277.454924  242.461530  17.047567  1175.163684\n",
      "median_k3     154.765350  151.627941   4.524897   747.926969\n",
      "median_k5     254.444854  245.079961   3.526483  1483.564549\n",
      "\n",
      "  Noise Level: scale_2.0\n",
      "                    mean         std        min          max\n",
      "Filter                                                      \n",
      "bilateral_k5  241.522493  213.023670  15.157089  1017.475269\n",
      "gaussian_k3   152.047990  135.224506  11.653261   547.752014\n",
      "gaussian_k5   212.464757  188.090573  13.780425   860.766051\n",
      "gaussian_k7   281.783274  244.114223  18.289103  1189.254506\n",
      "median_k3     162.611421  152.243921   7.559361   754.370328\n",
      "median_k5     258.892658  245.000342   4.950061  1474.620138\n",
      "\n",
      "  Noise Level: scale_5.0\n",
      "                    mean         std        min          max\n",
      "Filter                                                      \n",
      "bilateral_k5  258.449622  216.986902  20.413814  1056.196139\n",
      "gaussian_k3   173.827867  138.737166  18.912400   587.857974\n",
      "gaussian_k5   229.527187  192.200422  18.947456   902.829340\n",
      "gaussian_k7   296.835938  248.958044  22.012592  1227.598837\n",
      "median_k3     185.974992  156.213634  16.454717   776.861840\n",
      "median_k5     273.221090  247.450095   9.357108  1474.043918\n",
      "\n",
      "Entropy Difference from Original:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  Noise Level: scale_0.1\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.233646  0.316107  0.000268  1.376973\n",
      "gaussian_k3   0.193072  0.264841  0.000448  1.184698\n",
      "gaussian_k5   0.227185  0.308016  0.000056  1.360539\n",
      "gaussian_k7   0.266756  0.353143  0.000099  1.533677\n",
      "median_k3     0.114813  0.123504  0.003458  0.637853\n",
      "median_k5     0.136407  0.130974  0.006390  0.656975\n",
      "\n",
      "  Noise Level: scale_0.5\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.243597  0.320041  0.000269  1.390205\n",
      "gaussian_k3   0.205687  0.279392  0.000458  1.203661\n",
      "gaussian_k5   0.236731  0.312343  0.000123  1.366873\n",
      "gaussian_k7   0.273354  0.352523  0.000870  1.532312\n",
      "median_k3     0.126838  0.173023  0.000551  0.931746\n",
      "median_k5     0.142533  0.152691  0.003725  0.703803\n",
      "\n",
      "  Noise Level: scale_1.0\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.251057  0.325981  0.000295  1.393475\n",
      "gaussian_k3   0.213396  0.292432  0.000179  1.208003\n",
      "gaussian_k5   0.243922  0.317917  0.000025  1.371980\n",
      "gaussian_k7   0.279667  0.353932  0.000101  1.529448\n",
      "median_k3     0.135394  0.203156  0.001348  1.270057\n",
      "median_k5     0.145442  0.173839  0.003616  0.884205\n",
      "\n",
      "  Noise Level: scale_2.0\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.258429  0.334835  0.000011  1.394404\n",
      "gaussian_k3   0.225036  0.309735  0.000715  1.356257\n",
      "gaussian_k5   0.251241  0.326794  0.000147  1.370495\n",
      "gaussian_k7   0.284382  0.357926  0.000910  1.528284\n",
      "median_k3     0.156104  0.235248  0.001102  1.584518\n",
      "median_k5     0.160498  0.193485  0.003449  1.168989\n",
      "\n",
      "  Noise Level: scale_5.0\n",
      "                  mean       std       min       max\n",
      "Filter                                              \n",
      "bilateral_k5  0.272845  0.353814  0.001466  1.468464\n",
      "gaussian_k3   0.246856  0.340788  0.001480  1.714712\n",
      "gaussian_k5   0.265802  0.345255  0.003325  1.438316\n",
      "gaussian_k7   0.295928  0.365611  0.000397  1.512734\n",
      "median_k3     0.181922  0.286236  0.000129  1.982142\n",
      "median_k5     0.181047  0.234084  0.007735  1.632945\n",
      "\n",
      "======================================================================\n",
      "All visualizations saved to: ../../Data_Results/Data\\bar_graphs\\poisson\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============ CREATE METRIC HISTOGRAMS ============\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CREATING METRIC DISTRIBUTION VISUALIZATIONS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Load all denoised CSV files\n",
    "all_denoised_data = []\n",
    "\n",
    "for csv_file in os.listdir(metrics_root):\n",
    "    if csv_file.startswith('denoised_') and csv_file.endswith('.csv'):\n",
    "        csv_path = os.path.join(metrics_root, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        all_denoised_data.append(df)\n",
    "\n",
    "if all_denoised_data:\n",
    "    # Combine all data into single DataFrame\n",
    "    combined_df = pd.concat(all_denoised_data, ignore_index=True)\n",
    "    \n",
    "    print(f\"Loaded {len(all_denoised_data)} CSV files\")\n",
    "    print(f\"Total records: {len(combined_df)}\")\n",
    "    print(f\"Noise levels: {sorted(combined_df['Noise_Level'].unique())}\")\n",
    "    print(f\"Filters tested: {sorted(combined_df['Filter'].unique())}\")\n",
    "    \n",
    "    # Define metrics to visualize\n",
    "    metrics_to_plot = [\n",
    "        ('Denoised_PSNR', 'PSNR (dB)', 'Peak Signal-to-Noise Ratio'),\n",
    "        ('Denoised_SSIM', 'SSIM', 'Structural Similarity Index'),\n",
    "        ('Denoised_MSE', 'MSE', 'Mean Squared Error'),\n",
    "        ('Denoised_Entropy_Diff', 'Entropy Difference', 'Entropy Difference from Original')\n",
    "    ]\n",
    "    \n",
    "    # Get sorted noise levels and unique filter types\n",
    "    noise_levels_sorted = sorted(combined_df['Noise_Level'].unique(), \n",
    "                                 key=lambda x: float(x.split('_')[1]))\n",
    "    \n",
    "    # Group filters by type (extract base filter name)\n",
    "    filter_types = {}\n",
    "    for filter_name in combined_df['Filter'].unique():\n",
    "        base_type = filter_name.rsplit('_', 1)[0]  # e.g., 'gaussian_k3' -> 'gaussian'\n",
    "        if base_type not in filter_types:\n",
    "            filter_types[base_type] = []\n",
    "        filter_types[base_type].append(filter_name)\n",
    "    \n",
    "    # Sort filters within each type by kernel size\n",
    "    for base_type in filter_types:\n",
    "        filter_types[base_type] = sorted(filter_types[base_type], \n",
    "                                        key=lambda x: int(x.split('_k')[1]))\n",
    "    \n",
    "    # Create visualization for each metric\n",
    "    for metric_col, xlabel, title in metrics_to_plot:\n",
    "        if metric_col not in combined_df.columns:\n",
    "            print(f\"  Warning: Skipping {metric_col} - column not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nCreating visualizations for {title}...\")\n",
    "        \n",
    "        # ===== CREATE GRID: Noise Levels (rows) × Filter Types (columns) =====\n",
    "        n_noise_levels = len(noise_levels_sorted)\n",
    "        n_filter_types = len(filter_types)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_noise_levels, n_filter_types, \n",
    "                                figsize=(6*n_filter_types, 4*n_noise_levels))\n",
    "        fig.suptitle(f'{title} Distribution by Noise Level and Filter Type', \n",
    "                     fontsize=18, fontweight='bold', y=0.995)\n",
    "        \n",
    "        # Ensure axes is 2D even if only 1 row or column\n",
    "        if n_noise_levels == 1 and n_filter_types == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif n_noise_levels == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        elif n_filter_types == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        \n",
    "        # Create color map for kernel sizes\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "        \n",
    "        # Plot each combination of noise level and filter type\n",
    "        for row_idx, noise_level in enumerate(noise_levels_sorted):\n",
    "            for col_idx, (base_type, filter_list) in enumerate(sorted(filter_types.items())):\n",
    "                ax = axes[row_idx, col_idx]\n",
    "                \n",
    "                # Plot histogram for each kernel size in this filter type\n",
    "                for filter_idx, filter_name in enumerate(filter_list):\n",
    "                    data_subset = combined_df[\n",
    "                        (combined_df['Noise_Level'] == noise_level) & \n",
    "                        (combined_df['Filter'] == filter_name)\n",
    "                    ][metric_col]\n",
    "                    \n",
    "                    if len(data_subset) > 0:\n",
    "                        kernel_size = filter_name.split('_k')[1]\n",
    "                        ax.hist(data_subset, alpha=0.6, bins=15, \n",
    "                               color=colors[filter_idx % len(colors)],\n",
    "                               label=f'kernel={kernel_size}', \n",
    "                               edgecolor='black', linewidth=0.5)\n",
    "                \n",
    "                # Formatting\n",
    "                ax.set_xlabel(xlabel, fontsize=9)\n",
    "                ax.set_ylabel('Frequency', fontsize=9)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Title for top row only\n",
    "                if row_idx == 0:\n",
    "                    ax.set_title(f'{base_type.capitalize()} Filter', \n",
    "                                fontsize=11, fontweight='bold')\n",
    "                \n",
    "                # Y-axis label for first column only\n",
    "                if col_idx == 0:\n",
    "                    ax.text(-0.3, 0.5, f'{noise_level}\\n(scale={noise_level.split(\"_\")[1]})', \n",
    "                           transform=ax.transAxes, fontsize=10, fontweight='bold',\n",
    "                           verticalalignment='center', rotation=90)\n",
    "                \n",
    "                # Add legend if there are multiple kernel sizes\n",
    "                if len(filter_list) > 1:\n",
    "                    ax.legend(fontsize=8, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        output_filename = f\"histogram_{metric_col.lower()}_detailed.png\"\n",
    "        output_path = os.path.join(graph_root, output_filename)\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved: {output_filename}\")\n",
    "    \n",
    "    # Print summary statistics organized by noise level and filter\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for metric_col, _, title in metrics_to_plot:\n",
    "        if metric_col in combined_df.columns:\n",
    "            print(f\"\\n{title}:\")\n",
    "            print(\"-\" * 70)\n",
    "            for noise_level in noise_levels_sorted:\n",
    "                print(f\"\\n  Noise Level: {noise_level}\")\n",
    "                subset = combined_df[combined_df['Noise_Level'] == noise_level]\n",
    "                summary = subset.groupby('Filter')[metric_col].agg(['mean', 'std', 'min', 'max'])\n",
    "                print(summary.to_string())\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"All visualizations saved to: {graph_root}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Warning: No denoised CSV files found. Run the main processing loop first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING AGGREGATED HEATMAP VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "Creating heatmap for PSNR (dB)...\n",
      "  Saved: heatmap_denoised_psnr_aggregated.png\n",
      "Creating heatmap for SSIM...\n",
      "  Saved: heatmap_denoised_ssim_aggregated.png\n",
      "Creating heatmap for MSE...\n",
      "  Saved: heatmap_denoised_mse_aggregated.png\n",
      "Creating heatmap for Entropy Difference...\n",
      "  Saved: heatmap_denoised_entropy_diff_aggregated.png\n",
      "Creating heatmap for Noise Variance...\n",
      "  Saved: heatmap_denoised_noise_variance_aggregated.png\n",
      "Creating heatmap for Sharpness...\n",
      "  Saved: heatmap_denoised_sharpness_aggregated.png\n",
      "Creating heatmap for Spatial Frequency...\n",
      "  Saved: heatmap_denoised_spatial_freq_aggregated.png\n",
      "Creating heatmap for Dynamic Range...\n",
      "  Saved: heatmap_denoised_dynamic_range_aggregated.png\n",
      "\n",
      "======================================================================\n",
      "All aggregated heatmaps saved to: ../../Data_Results/Data\\bar_graphs\\poisson\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============ CREATE AGGREGATED HEATMAP VISUALIZATIONS ============\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CREATING AGGREGATED HEATMAP VISUALIZATIONS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Load all denoised CSV files\n",
    "all_denoised_data = []\n",
    "\n",
    "for csv_file in os.listdir(metrics_root):\n",
    "    if csv_file.startswith('denoised_') and csv_file.endswith('.csv'):\n",
    "        csv_path = os.path.join(metrics_root, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        all_denoised_data.append(df)\n",
    "\n",
    "if all_denoised_data:\n",
    "    # Combine all data into single DataFrame\n",
    "    combined_df = pd.concat(all_denoised_data, ignore_index=True)\n",
    "    \n",
    "    # Define metrics to visualize\n",
    "    metrics_to_plot = [\n",
    "        ('Denoised_PSNR', 'PSNR (dB)', 'higher_better'),\n",
    "        ('Denoised_SSIM', 'SSIM', 'higher_better'),\n",
    "        ('Denoised_MSE', 'MSE', 'lower_better'),\n",
    "        ('Denoised_Entropy_Diff', 'Entropy Difference', 'lower_better'),\n",
    "        ('Denoised_Noise_Variance', 'Noise Variance', 'lower_better'),\n",
    "        ('Denoised_Sharpness', 'Sharpness', 'higher_better'),\n",
    "        ('Denoised_Spatial_Freq', 'Spatial Frequency', 'higher_better'),\n",
    "        ('Denoised_Dynamic_Range', 'Dynamic Range', 'higher_better')\n",
    "    ]\n",
    "    \n",
    "    # Get sorted noise levels\n",
    "    noise_levels_sorted = sorted(combined_df['Noise_Level'].unique(), \n",
    "                                 key=lambda x: float(x.split('_')[1]))\n",
    "    \n",
    "    # Get sorted filter names\n",
    "    filters_sorted = sorted(combined_df['Filter'].unique())\n",
    "    \n",
    "    # Create heatmap for each metric\n",
    "    for metric_col, metric_label, better_direction in metrics_to_plot:\n",
    "        if metric_col not in combined_df.columns:\n",
    "            print(f\"  Warning: Skipping {metric_col} - column not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Creating heatmap for {metric_label}...\")\n",
    "        \n",
    "        # Create figure with subplots: Overall at top + one for each scale\n",
    "        n_scales = len(noise_levels_sorted)\n",
    "        fig, axes = plt.subplots(n_scales + 1, 1, figsize=(12, 4 * (n_scales + 1)))\n",
    "        fig.suptitle(f'{metric_label} vs Filter Type - Aggregated Heatmaps', \n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        # ===== OVERALL AGGREGATED HEATMAP (across all scales) =====\n",
    "        overall_data = combined_df.groupby('Filter')[metric_col].mean().reindex(filters_sorted)\n",
    "        overall_matrix = overall_data.values.reshape(1, -1)\n",
    "        \n",
    "        # Choose colormap based on whether higher or lower is better\n",
    "        if better_direction == 'higher_better':\n",
    "            cmap = 'RdYlGn'  # Red (low) to Green (high)\n",
    "        else:\n",
    "            cmap = 'RdYlGn_r'  # Green (low) to Red (high)\n",
    "        \n",
    "        sns.heatmap(overall_matrix, ax=axes[0], annot=True, fmt='.2f', \n",
    "                   cmap=cmap, cbar_kws={'label': metric_label},\n",
    "                   xticklabels=filters_sorted, yticklabels=['Overall Average'],\n",
    "                   linewidths=0.5, linecolor='gray')\n",
    "        axes[0].set_title(f'Overall Average {metric_label} (All Scales)', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xlabel('Filter Type', fontsize=10)\n",
    "        \n",
    "        # ===== HEATMAP FOR EACH SCALE =====\n",
    "        for idx, noise_level in enumerate(noise_levels_sorted):\n",
    "            ax = axes[idx + 1]\n",
    "            \n",
    "            # Get data for this noise level\n",
    "            scale_data = combined_df[combined_df['Noise_Level'] == noise_level]\n",
    "            scale_matrix = scale_data.groupby('Filter')[metric_col].mean().reindex(filters_sorted)\n",
    "            scale_matrix = scale_matrix.values.reshape(1, -1)\n",
    "            \n",
    "            # Create heatmap\n",
    "            sns.heatmap(scale_matrix, ax=ax, annot=True, fmt='.2f', \n",
    "                       cmap=cmap, cbar_kws={'label': metric_label},\n",
    "                       xticklabels=filters_sorted, yticklabels=[f'{noise_level}'],\n",
    "                       linewidths=0.5, linecolor='gray')\n",
    "            \n",
    "            scale_value = noise_level.split('_')[1]\n",
    "            ax.set_title(f'{metric_label} at Scale {scale_value}', \n",
    "                        fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Filter Type', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        output_filename = f\"heatmap_{metric_col.lower()}_aggregated.png\"\n",
    "        output_path = os.path.join(graph_root, output_filename)\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved: {output_filename}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"All aggregated heatmaps saved to: {graph_root}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Warning: No denoised CSV files found. Run the main processing loop first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Configurations tested:\n",
      "  - Poisson noise levels: 5\n",
      "  - Anscombe denoising filters: 6\n",
      "  - Total combinations: 30\n",
      "\n",
      "Images processed:\n",
      "  - Color images: 80\n",
      "  - B&W images: 80\n",
      "  - Total images: 160\n",
      "  - Sample images: 5\n",
      "\n",
      "Output locations:\n",
      "  - Metrics (CSV files): ../../Data_Results/Data\\noised_image_data\\poisson\n",
      "  - Noisy images (Color): ../../Photos_Subset/Noised_Images/Color\n",
      "  - Noisy images (B&W): ../../Photos_Subset/Noised_Images/BW\n",
      "  - Sample comparisons: ../../Data_Results/Data\\finished\\poisson\n",
      "  - Visualizations (histograms & heatmaps): ../../Data_Results/Data\\bar_graphs\\poisson\n",
      "\n",
      "CSV files created:\n",
      "  - Noisy metrics: 10 files (color + B&W)\n",
      "  - Denoised metrics: 60 files\n",
      "\n",
      "Visualizations created:\n",
      "  - Detailed histograms: 4 files\n",
      "  - Aggregated heatmaps: 8 files (one per metric)\n",
      "  - Sample image comparisons: 25 files\n",
      "\n",
      "All tasks completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============ FINAL SUMMARY ============\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"PROCESSING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nConfigurations tested:\")\n",
    "print(f\"  - Poisson noise levels: {len(POISSON_PARAMS)}\")\n",
    "print(f\"  - Anscombe denoising filters: {len(ANSCOMBE_FILTERS)}\")\n",
    "print(f\"  - Total combinations: {len(POISSON_PARAMS) * len(ANSCOMBE_FILTERS)}\")\n",
    "print(f\"\\nImages processed:\")\n",
    "print(f\"  - Color images: {len(color_files)}\")\n",
    "print(f\"  - B&W images: {len(bw_files)}\")\n",
    "print(f\"  - Total images: {len(all_files)}\")\n",
    "print(f\"  - Sample images: {len(sample_images)}\")\n",
    "print(f\"\\nOutput locations:\")\n",
    "print(f\"  - Metrics (CSV files): {metrics_root}\")\n",
    "print(f\"  - Noisy images (Color): {noised_root_color}\")\n",
    "print(f\"  - Noisy images (B&W): {noised_root_bw}\")\n",
    "print(f\"  - Sample comparisons: {sample_root}\")\n",
    "print(f\"  - Visualizations (histograms & heatmaps): {graph_root}\")\n",
    "print(f\"\\nCSV files created:\")\n",
    "print(f\"  - Noisy metrics: {len(POISSON_PARAMS) * 2} files (color + B&W)\")\n",
    "print(f\"  - Denoised metrics: {len(POISSON_PARAMS) * len(ANSCOMBE_FILTERS) * 2} files\")\n",
    "print(f\"\\nVisualizations created:\")\n",
    "print(f\"  - Detailed histograms: 4 files\")\n",
    "print(f\"  - Aggregated heatmaps: 8 files (one per metric)\")\n",
    "print(f\"  - Sample image comparisons: {len(sample_images) * len(POISSON_PARAMS)} files\")\n",
    "print(f\"\\nAll tasks completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Summary\n",
    "\n",
    "Displays a summary of all processing completed and output locations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
